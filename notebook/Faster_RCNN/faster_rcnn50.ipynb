{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc67b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1: 100%|██████████| 65/65 [00:07<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sul test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 33.0811\n",
      "Score sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:05<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "map_50: 0.22118432819843292\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 65/65 [00:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sul test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 13/13 [00:05<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 19.3014\n",
      "Score sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:05<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "map_50: 0.7706699371337891\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 65/65 [00:07<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sul test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 13/13 [00:05<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 15.6455\n",
      "Score sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:05<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "map_50: 0.7119864225387573\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 65/65 [00:06<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sul test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 13/13 [00:05<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 12.6586\n",
      "Score sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "map_50: 0.8167600631713867\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 65/65 [00:07<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss sul test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 13/13 [00:05<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 10.4907\n",
      "Score sul valid set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:05<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "map_50: 0.8467138409614563\n",
      "\n",
      "\n",
      "Training complete. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edoardo\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\utils.py:211: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved prediction to: results/predictions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, root, image_set=\"train\", transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        image_set_file = os.path.join(root, \"ImageSets\", \"Main\", f\"{image_set}.txt\")\n",
    "        with open(image_set_file) as f:\n",
    "            self.image_ids = [x.strip() for x in f.readlines()]\n",
    "        self.img_dir = os.path.join(root, \"JPEGImages\")\n",
    "        self.ann_dir = os.path.join(root, \"Annotations\")\n",
    "        self.classes = [\"__background__\"] + self._find_classes()\n",
    "        self.image_files = sorted([f for f in os.listdir(self.img_dir) if f.endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    def _find_classes(self):\n",
    "        cls = set()\n",
    "        for fname in os.listdir(self.ann_dir):\n",
    "            tree = ET.parse(os.path.join(self.ann_dir, fname))\n",
    "            for obj in tree.findall(\"object\"):\n",
    "                cls.add(obj.find(\"name\").text)\n",
    "        return sorted(list(cls))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{image_id}.jpg\")\n",
    "        ann_path = os.path.join(self.ann_dir, f\"{image_id}.xml\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes, labels = [], []\n",
    "        for obj in root.findall(\"object\"):\n",
    "            label = obj.find(\"name\").text\n",
    "            labels.append(self.classes.index(label))\n",
    "\n",
    "            bndbox = obj.find(\"bndbox\")\n",
    "            bbox = [\n",
    "                float(bndbox.find(\"xmin\").text),\n",
    "                float(bndbox.find(\"ymin\").text),\n",
    "                float(bndbox.find(\"xmax\").text),\n",
    "                float(bndbox.find(\"ymax\").text),\n",
    "            ]\n",
    "            boxes.append(bbox)\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            # 🔁 Prova a caricare un'altra immagine se questa è vuota\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "            \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)   \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "def evaluate_metrics(model, data_loader, device,epoch, csv_path=\"results/metrics.csv\"):\n",
    "    mAP50 = 0.0\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision()\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "            metric.update(outputs, targets)\n",
    "\n",
    "    results = metric.compute()\n",
    "\n",
    "    # Print\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    for k, v in results.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            if(k==\"map_50\"):\n",
    "                print(f\"{k}: {v.item() if v.numel() == 1 else v}\")\n",
    "                mAP50 = v.item()\n",
    "    metric.reset()\n",
    "    # Save to CSV\n",
    "    summary = {k: v.item() if isinstance(v, torch.Tensor) and v.numel() == 1 else str(v)\n",
    "               for k, v in results.items()}\n",
    "    #summary[\"epoch\"] = epoch\n",
    "    summary = dict([(\"epoch\", epoch)] + list(summary.items()))\n",
    "    df = pd.DataFrame([summary])\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', header=write_header, index=False)\n",
    "    #print(f\"\\nSaved metrics to: {csv_path}\")\n",
    "    return mAP50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "def show_predictions(model, dataset, device, score_threshold=0.25):\n",
    "    model.eval()\n",
    "    output_dir=\"results/predictions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, target = dataset[idx]\n",
    "        img_tensor = img.to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)[0]\n",
    "\n",
    "        # Filtro predizioni con punteggio basso\n",
    "        keep = output['scores'] >= score_threshold\n",
    "        pred_boxes = output['boxes'][keep].cpu()\n",
    "        pred_labels = output['labels'][keep].cpu()\n",
    "        scores = output['scores'][keep].cpu()\n",
    "\n",
    "        # Disegna box predetti\n",
    "        pred_img = draw_bounding_boxes((img * 255).byte(), pred_boxes, labels=[f\"P:{l.item()}\" for l in pred_labels],\n",
    "                                       colors=\"red\", width=1)\n",
    "\n",
    "        # Disegna box reali\n",
    "        # true_boxes = target['boxes'].cpu()\n",
    "        # true_labels = target['labels'].cpu()\n",
    "        # full_img = draw_bounding_boxes(pred_img, true_boxes, labels=[f\"T:{l.item()}\" for l in true_labels],\n",
    "        #                                colors=\"green\", width=2)\n",
    "\n",
    "        \n",
    "\n",
    "        # Nome originale immagine\n",
    "        original_filename = dataset.image_files[idx] # Es: \"img001.jpg\"\n",
    "        output_filename = os.path.splitext(original_filename)[0] + \"_pred.jpg\"\n",
    "\n",
    "        # Salva immagine\n",
    "        img_pil = to_pil_image(pred_img)\n",
    "        img_pil.save(os.path.join(output_dir, output_filename))\n",
    "        \n",
    "    print(f\"saved prediction to: {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    gc.collect()\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    dataset_root = \"dataset\"\n",
    "    save_weights_dir = \"results/weights\"\n",
    "    num_epochs = 5\n",
    "    writer = SummaryWriter(\"logs/faster_rcnn50\")\n",
    "\n",
    "    transforms = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset_train = VOCDataset(dataset_root, image_set=\"train\", transforms=transforms)\n",
    "    dataset_valid = VOCDataset(dataset_root, image_set=\"val\", transforms=transforms)\n",
    "    dataset_test = VOCDataset(dataset_root, image_set=\"test\", transforms=transforms)\n",
    "    data_loader_train = DataLoader(dataset_train, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "    data_loader_valid = DataLoader(dataset_valid, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "    #data_loader_test = DataLoader(dataset_test, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    model = get_model(num_classes=len(dataset_train.classes))\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_score_valid = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_loss_valid = 0.0\n",
    "\n",
    "        for images, targets in tqdm(data_loader_train, desc=f\"Epoch {epoch+1}\"):\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += losses.item()\n",
    "        print(\"Loss sul test set:\")\n",
    "        for images, targets in tqdm(data_loader_valid, desc=f\"Epoch {epoch+1}\"):\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            total_loss_valid += losses.item()\n",
    "\n",
    "            \n",
    "        writer.add_scalar(\"loss/train\", total_loss, epoch+1)\n",
    "        writer.add_scalar(\"loss/valid\", total_loss_valid, epoch+1)\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "        #EVALUATION PER EPOCA SUL TRAIN SET\n",
    "        # print(\"Score sul train set:\")\n",
    "        # evaluate_metrics(model, data_loader_train, device, epoch=epoch+1,csv_path=\"results/train_metrics.csv\")\n",
    "\n",
    "        #EVALUATION PER EPOCA SUL VALID SET\n",
    "        print(\"Score sul valid set:\")\n",
    "        current_score_valid = evaluate_metrics(model, data_loader_valid, device, epoch=epoch+1,csv_path=\"results/valid_metrics.csv\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        os.makedirs(save_weights_dir, exist_ok=True)\n",
    "        torch.cuda.empty_cache()\n",
    "        if current_score_valid > best_score_valid:\n",
    "            best_score_valid = current_score_valid\n",
    "            torch.save(model.state_dict(), \"results/weights/fasterrcnn_voc_best.pth\")\n",
    "            #print(f\"New best model saved with score: {best_score:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), \"results/weights/fasterrcnn_voc_last.pth\")\n",
    "\n",
    "    print(\"Training complete. Model saved.\")\n",
    "    #fase di inferenza\n",
    "    \n",
    "    show_predictions(model,dataset_test,device=device,score_threshold=0.25)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "#mettere nel file csv le metriche di ogni epoca ✅\n",
    "#inserire weight and biases (oppure tensorboard) ✅\n",
    "#salvare il best.pth del modello ✅\n",
    "#fare la evaluation sul valid set oltre a quella di train(aggiungi la loss/val su tensorboard), salvare il best.pth in base alla map sul valid set(segna epoca nel file) ✅\n",
    "#refactor con divisione in celle, oppure vari file.py\n",
    "#dare le etichette nelle classi \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc136765",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
